{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "291a6f53",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#分词\" data-toc-modified-id=\"分词-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>分词</a></span></li><li><span><a href=\"#关键词提取\" data-toc-modified-id=\"关键词提取-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>关键词提取</a></span></li><li><span><a href=\"#向量化\" data-toc-modified-id=\"向量化-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>向量化</a></span></li><li><span><a href=\"#Gensim\" data-toc-modified-id=\"Gensim-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Gensim</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f5edd0",
   "metadata": {},
   "source": [
    "# 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c812bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\lenovo\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.802 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "#encoding=utf-8\n",
    "from __future__ import print_function, unicode_literals\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import jieba\n",
    "jieba.load_userdict(\"user_dict.txt\")\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "jieba.add_word('石墨烯')\n",
    "jieba.add_word('凱特琳')\n",
    "jieba.del_word('自定义词')\n",
    "\n",
    "test_sent = (\n",
    "\"李小福是创新办主任也是云计算方面的专家; 什么是八一双鹿\\n\"\n",
    "\"例如我输入一个带“韩玉赏鉴”的标题，在自定义词库中也增加了此词为N类\\n\"\n",
    "\"「台中」正確應該不會被切開。mac上可分出「石墨烯」；此時又可以分出來凱特琳了。\"\n",
    ")\n",
    "words = jieba.cut(test_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f0010fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李小福/是/创新/办/主任/也/是/云/计算/方面/的/专家/;/ /什么/是/八/一双/鹿/\n",
      "/例如/我/输入/一个/带/“/韩玉/赏鉴/”/的/标题/，/在/自定义/词库/中/也/增加/了/此/词为/N/类/\n",
      "/「/台/中/」/正確/應該/不會/被/切開/。/mac/上/可/分出/「/石墨烯/」/；/此時/又/可以/分出/來/凱特琳/了/。\n"
     ]
    }
   ],
   "source": [
    "print('/'.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7620adf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李小福 / nr ,  是 / v ,  创新 / v ,  办 / v ,  主任 / b ,  也 / d ,  是 / v ,  云 / n ,  计算 / v ,  方面 / n ,  的 / uj ,  专家 / n ,  ; / x ,    / x ,  什么 / r ,  是 / v ,  八 / m ,  一双 / m ,  鹿 / nr ,  \n",
      " / x ,  例如 / v ,  我 / r ,  输入 / v ,  一个 / m ,  带 / v ,  “ / x ,  韩玉 / nr ,  赏鉴 / v ,  ” / x ,  的 / uj ,  标题 / n ,  ， / x ,  在 / p ,  自定义 / l ,  词库 / n ,  中 / f ,  也 / d ,  增加 / v ,  了 / ul ,  此 / r ,  词 / n ,  为 / p ,  N / eng ,  类 / q ,  \n",
      " / x ,  「 / x ,  台 / q ,  中 / f ,  」 / x ,  正確 / ad ,  應該 / v ,  不 / d ,  會 / v ,  被 / p ,  切開 / ad ,  。 / x ,  mac / eng ,  上 / f ,  可 / v ,  分出 / v ,  「 / x ,  石墨烯 / x ,  」 / x ,  ； / x ,  此時 / c ,  又 / d ,  可以 / c ,  分出 / v ,  來 / zg ,  凱特琳 / x ,  了 / ul ,  。 / x ,  "
     ]
    }
   ],
   "source": [
    "result = pseg.cut(test_sent)\n",
    "\n",
    "for w in result:\n",
    "    print(w.word, \"/\", w.flag, \", \", end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "697964bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "easy/_/install/ /is/ /great\n",
      "python/ /的/正则表达式/是/好/用/的\n",
      "========================================\n",
      "今天天气/不错\n",
      "今天天气 Before: 3, After: 0\n",
      "今天/天气/不错\n",
      "----------------------------------------\n",
      "如果/放到/post/中将/出错/。\n",
      "中将 Before: 763, After: 490\n",
      "如果/放到/post/中/将/出错/。\n",
      "----------------------------------------\n",
      "我们/中/出/了/一个/叛徒\n",
      "中出 Before: 3, After: 3\n",
      "我们/中/出/了/一个/叛徒\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "terms = jieba.cut('easy_install is great')\n",
    "print('/'.join(terms))\n",
    "terms = jieba.cut('python 的正则表达式是好用的')\n",
    "print('/'.join(terms))\n",
    "\n",
    "print(\"=\"*40)\n",
    "# test frequency tune\n",
    "testlist = [\n",
    "('今天天气不错', ('今天', '天气')),\n",
    "('如果放到post中将出错。', ('中', '将')),\n",
    "('我们中出了一个叛徒', ('中', '出')),\n",
    "]\n",
    "\n",
    "for sent, seg in testlist:\n",
    "    print('/'.join(jieba.cut(sent, HMM=False)))\n",
    "    word = ''.join(seg)\n",
    "    print('%s Before: %s, After: %s' % (word, jieba.get_FREQ(word), jieba.suggest_freq(seg, True)))\n",
    "    print('/'.join(jieba.cut(sent, HMM=False)))\n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5158bad1",
   "metadata": {},
   "source": [
    "# 关键词提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3b1437b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage:    python extract_tags.py [file name] -k [top k]\n",
      "\n",
      "ipykernel_launcher.py: error: no such option: -f\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\optparse.py\", line 1387, in parse_args\n",
      "    stop = self._process_args(largs, rargs, values)\n",
      "  File \"D:\\Anaconda\\lib\\optparse.py\", line 1431, in _process_args\n",
      "    self._process_short_opts(rargs, values)\n",
      "  File \"D:\\Anaconda\\lib\\optparse.py\", line 1513, in _process_short_opts\n",
      "    raise BadOptionError(opt)\n",
      "optparse.BadOptionError: no such option: -f\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_18400\\2222898026.py\", line 12, in <module>\n",
      "    opt, args = parser.parse_args()\n",
      "  File \"D:\\Anaconda\\lib\\optparse.py\", line 1389, in parse_args\n",
      "    self.error(str(err))\n",
      "  File \"D:\\Anaconda\\lib\\optparse.py\", line 1569, in error\n",
      "    self.exit(2, \"%s: error: %s\\n\" % (self.get_prog_name(), msg))\n",
      "  File \"D:\\Anaconda\\lib\\optparse.py\", line 1559, in exit\n",
      "    sys.exit(status)\n",
      "SystemExit: 2\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\Anaconda\\lib\\inspect.py\", line 1543, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadOptionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda\\lib\\optparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[1;34m(self, args, values)\u001b[0m\n\u001b[0;32m   1386\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1387\u001b[1;33m             \u001b[0mstop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1388\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mBadOptionError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOptionValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\optparse.py\u001b[0m in \u001b[0;36m_process_args\u001b[1;34m(self, largs, rargs, values)\u001b[0m\n\u001b[0;32m   1430\u001b[0m                 \u001b[1;31m# value(s) for the last one only)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1431\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_short_opts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1432\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallow_interspersed_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\optparse.py\u001b[0m in \u001b[0;36m_process_short_opts\u001b[1;34m(self, rargs, values)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moption\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1513\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mBadOptionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1514\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0moption\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtakes_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBadOptionError\u001b[0m: no such option: -f",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18400\\2222898026.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-k\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"topK\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\optparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[1;34m(self, args, values)\u001b[0m\n\u001b[0;32m   1388\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mBadOptionError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOptionValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\optparse.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m   1568\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_usage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1569\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"%s: error: %s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_prog_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\optparse.py\u001b[0m in \u001b[0;36mexit\u001b[1;34m(self, status, msg)\u001b[0m\n\u001b[0;32m   1558\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1559\u001b[1;33m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2068\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[0;32m   2069\u001b[0m                            'the full traceback.\\n']\n\u001b[1;32m-> 2070\u001b[1;33m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[0;32m   2071\u001b[0m                                                                      value))\n\u001b[0;32m   2072\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \"\"\"\n\u001b[1;32m--> 754\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m             out_list = (\n\u001b[1;32m--> 629\u001b[1;33m                 self.structured_traceback(\n\u001b[0m\u001b[0;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0metb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m             )\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "from optparse import OptionParser\n",
    "\n",
    "USAGE = \"usage:    python extract_tags.py [file name] -k [top k]\"\n",
    "\n",
    "parser = OptionParser(USAGE)\n",
    "parser.add_option(\"-k\", dest=\"topK\")\n",
    "opt, args = parser.parse_args()\n",
    "\n",
    "\n",
    "if len(args) < 1:\n",
    "    print(USAGE)\n",
    "    sys.exit(1)\n",
    "\n",
    "file_name = args[0]\n",
    "\n",
    "if opt.topK is None:\n",
    "    topK = 10\n",
    "else:\n",
    "    topK = int(opt.topK)\n",
    "\n",
    "content = open(file_name, 'rb').read()\n",
    "\n",
    "tags = jieba.analyse.extract_tags(content, topK=topK)\n",
    "\n",
    "print(\",\".join(tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38ce86e",
   "metadata": {},
   "source": [
    "# 向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "589856c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import  CountVectorizer, TfidfTransformer\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25fafa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('huike_newsdata-4.csv', nrows = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e516376",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['Title'] + data['Content']\n",
    "data = data[['Date', 'text']]\n",
    "data.columns = ['date', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0476ff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set()\n",
    "with open(\"stopwords.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        stopwords.add(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2de86a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_word(sent):\n",
    "    line = ''.join(sent)\n",
    "    chinese_chars = re.findall(r'[\\u4e00-\\u9fa5]+', line)\n",
    "    line = ''.join(chinese_chars)\n",
    "    jieba.load_userdict(\"user_dict_new.txt\")\n",
    "    wordList = jieba.lcut(line,cut_all=False)\n",
    "    return ' '.join([word for word in wordList if word not in stopwords and len(word)>1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5dca3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\lenovo\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.781 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "data['fenci_result'] = data.text.apply(cut_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f98ae056",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data_test_0405.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef7755d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 14 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel \n",
    "pandarallel.initialize(progress_bar= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5853cee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = {}\n",
    "for index, row in data.iterrows():\n",
    "    words = row['fenci_result'].split()\n",
    "    for word in words:\n",
    "        word_counts[word] = word_counts.get(word, 0) + 1\n",
    "filtered_words = [word for word, count in word_counts.items() if count >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd8eaaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return ' '.join([word for word in x.split() if word in filtered_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f2b9e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c173144988b7450f8f0207728a7fefab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1), Label(value='0 / 1'))), HBox(c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'filtered_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"D:\\Anaconda\\lib\\multiprocessing\\pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"D:\\Anaconda\\lib\\multiprocessing\\pool.py\", line 51, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\n  File \"D:\\Anaconda\\lib\\site-packages\\pandarallel\\core.py\", line 158, in __call__\n    results = self.work_function(\n  File \"D:\\Anaconda\\lib\\site-packages\\pandarallel\\data_types\\series.py\", line 26, in work\n    return data.apply(\n  File \"D:\\Anaconda\\lib\\site-packages\\pandas\\core\\series.py\", line 4771, in apply\n    return SeriesApply(self, func, convert_dtype, args, kwargs).apply()\n  File \"D:\\Anaconda\\lib\\site-packages\\pandas\\core\\apply.py\", line 1105, in apply\n    return self.apply_standard()\n  File \"D:\\Anaconda\\lib\\site-packages\\pandas\\core\\apply.py\", line 1156, in apply_standard\n    mapped = lib.map_infer(\n  File \"pandas\\_libs\\lib.pyx\", line 2918, in pandas._libs.lib.map_infer\n  File \"D:\\Anaconda\\lib\\site-packages\\pandarallel\\progress_bars.py\", line 214, in closure\n    return user_defined_function(\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_13492\\2298865053.py\", line 2, in func\n  File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_13492\\2298865053.py\", line 2, in <listcomp>\nNameError: name 'filtered_words' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13492\\2947459975.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filtered_fenci_result'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fenci_result'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandarallel\\core.py\u001b[0m in \u001b[0;36mclosure\u001b[1;34m(data, user_defined_function, *user_defined_function_args, **user_defined_function_kwargs)\u001b[0m\n\u001b[0;32m    442\u001b[0m                 \u001b[0mprogress_bars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworker_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_promise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_extra\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    769\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filtered_words' is not defined"
     ]
    }
   ],
   "source": [
    "data['filtered_fenci_result'] = data['fenci_result'].parallel_apply(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04030429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>fenci_result</th>\n",
       "      <th>filtered_fenci_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>争夺数据库以 Oracle 为代表的外资数据库软件，在中国的垄断地位正被打破撰稿：刘沛林数据...</td>\n",
       "      <td>争夺 数据库 以为 代表 外资 数据库 软件 中国 垄断 地位 打破 撰稿 刘沛林 数据库 ...</td>\n",
       "      <td>数据库 以为 代表 外资 数据库 软件 中国 数据库 存储 计算 底层 硬件 之上 上层 应...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>京港金融合作机遇多文字快照：http://paper.ce.cn/pc/content/20...</td>\n",
       "      <td>京港 金融合作 机遇 文字 快照 本报讯 记者 韩秉志 诗阳 第二十五届 北京 香港 经济 ...</td>\n",
       "      <td>京港 机遇 文字 快照 记者 北京 香港 经济 合作 洽谈会 北京 香港 两地 洽谈会 融入...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>青岛崂山：全链条金融服务助力引育人才文字快照：http://epaper.gmw.cn/gm...</td>\n",
       "      <td>青岛 崂山 链条 金融服务 助力 引育 人才 文字 快照 免费 拎包 入住 感觉 真爽 外地...</td>\n",
       "      <td>青岛 金融服务 助力 人才 文字 快照 山东 青岛 工作 公司 人才 公寓 恒丰 理财 公司...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>坚守初心、回馈社会：光大银行全面推进 ESG 建设2004年，联合国环境规划署首次提出ESG...</td>\n",
       "      <td>坚守 回馈 社会 光大银行 全面 推进 建设 联合国环境规划署 首次 提出 环境 社会 责任...</td>\n",
       "      <td>坚守 回馈 社会 光大银行 全面 推进 建设 首次 提出 环境 社会 责任 理念 倡导 关注...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>\" 信 创 \"加 速美国技术封锁，国内政策支持，本土 IT产业链加速铺进关键行业与核心领域撰...</td>\n",
       "      <td>信创 加速 美国 技术 封锁 国内 政策 支持 本土 产业链 加速 铺进 关键 行业 核心 ...</td>\n",
       "      <td>信创 加速 美国 技术 国内 政策 支持 本土 产业链 加速 关键 行业 核心 领域 公司 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text  \\\n",
       "0  2022-12-19  争夺数据库以 Oracle 为代表的外资数据库软件，在中国的垄断地位正被打破撰稿：刘沛林数据...   \n",
       "1  2022-12-19  京港金融合作机遇多文字快照：http://paper.ce.cn/pc/content/20...   \n",
       "2  2022-12-19  青岛崂山：全链条金融服务助力引育人才文字快照：http://epaper.gmw.cn/gm...   \n",
       "3  2022-12-19  坚守初心、回馈社会：光大银行全面推进 ESG 建设2004年，联合国环境规划署首次提出ESG...   \n",
       "4  2022-12-19  \" 信 创 \"加 速美国技术封锁，国内政策支持，本土 IT产业链加速铺进关键行业与核心领域撰...   \n",
       "\n",
       "                                        fenci_result  \\\n",
       "0  争夺 数据库 以为 代表 外资 数据库 软件 中国 垄断 地位 打破 撰稿 刘沛林 数据库 ...   \n",
       "1  京港 金融合作 机遇 文字 快照 本报讯 记者 韩秉志 诗阳 第二十五届 北京 香港 经济 ...   \n",
       "2  青岛 崂山 链条 金融服务 助力 引育 人才 文字 快照 免费 拎包 入住 感觉 真爽 外地...   \n",
       "3  坚守 回馈 社会 光大银行 全面 推进 建设 联合国环境规划署 首次 提出 环境 社会 责任...   \n",
       "4  信创 加速 美国 技术 封锁 国内 政策 支持 本土 产业链 加速 铺进 关键 行业 核心 ...   \n",
       "\n",
       "                               filtered_fenci_result  \n",
       "0  数据库 以为 代表 外资 数据库 软件 中国 数据库 存储 计算 底层 硬件 之上 上层 应...  \n",
       "1  京港 机遇 文字 快照 记者 北京 香港 经济 合作 洽谈会 北京 香港 两地 洽谈会 融入...  \n",
       "2  青岛 金融服务 助力 人才 文字 快照 山东 青岛 工作 公司 人才 公寓 恒丰 理财 公司...  \n",
       "3  坚守 回馈 社会 光大银行 全面 推进 建设 首次 提出 环境 社会 责任 理念 倡导 关注...  \n",
       "4  信创 加速 美国 技术 国内 政策 支持 本土 产业链 加速 关键 行业 核心 领域 公司 ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ffd3b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5606"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.filtered_fenci_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ee504b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>fenci_result</th>\n",
       "      <th>filtered_fenci_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>争夺数据库以 Oracle 为代表的外资数据库软件，在中国的垄断地位正被打破撰稿：刘沛林数据...</td>\n",
       "      <td>争夺 数据库 以为 代表 外资 数据库 软件 中国 垄断 地位 打破 撰稿 刘沛林 数据库 ...</td>\n",
       "      <td>数据库 以为 代表 外资 数据库 软件 中国 数据库 存储 计算 底层 硬件 之上 上层 应...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>京港金融合作机遇多文字快照：http://paper.ce.cn/pc/content/20...</td>\n",
       "      <td>京港 金融合作 机遇 文字 快照 本报讯 记者 韩秉志 诗阳 第二十五届 北京 香港 经济 ...</td>\n",
       "      <td>京港 机遇 文字 快照 记者 北京 香港 经济 合作 洽谈会 北京 香港 两地 洽谈会 融入...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>青岛崂山：全链条金融服务助力引育人才文字快照：http://epaper.gmw.cn/gm...</td>\n",
       "      <td>青岛 崂山 链条 金融服务 助力 引育 人才 文字 快照 免费 拎包 入住 感觉 真爽 外地...</td>\n",
       "      <td>青岛 金融服务 助力 人才 文字 快照 山东 青岛 工作 公司 人才 公寓 恒丰 理财 公司...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>坚守初心、回馈社会：光大银行全面推进 ESG 建设2004年，联合国环境规划署首次提出ESG...</td>\n",
       "      <td>坚守 回馈 社会 光大银行 全面 推进 建设 联合国环境规划署 首次 提出 环境 社会 责任...</td>\n",
       "      <td>坚守 回馈 社会 光大银行 全面 推进 建设 首次 提出 环境 社会 责任 理念 倡导 关注...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>\" 信 创 \"加 速美国技术封锁，国内政策支持，本土 IT产业链加速铺进关键行业与核心领域撰...</td>\n",
       "      <td>信创 加速 美国 技术 封锁 国内 政策 支持 本土 产业链 加速 铺进 关键 行业 核心 ...</td>\n",
       "      <td>信创 加速 美国 技术 国内 政策 支持 本土 产业链 加速 关键 行业 核心 领域 公司 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text  \\\n",
       "0  2022-12-19  争夺数据库以 Oracle 为代表的外资数据库软件，在中国的垄断地位正被打破撰稿：刘沛林数据...   \n",
       "1  2022-12-19  京港金融合作机遇多文字快照：http://paper.ce.cn/pc/content/20...   \n",
       "2  2022-12-19  青岛崂山：全链条金融服务助力引育人才文字快照：http://epaper.gmw.cn/gm...   \n",
       "3  2022-12-19  坚守初心、回馈社会：光大银行全面推进 ESG 建设2004年，联合国环境规划署首次提出ESG...   \n",
       "4  2022-12-19  \" 信 创 \"加 速美国技术封锁，国内政策支持，本土 IT产业链加速铺进关键行业与核心领域撰...   \n",
       "\n",
       "                                        fenci_result  \\\n",
       "0  争夺 数据库 以为 代表 外资 数据库 软件 中国 垄断 地位 打破 撰稿 刘沛林 数据库 ...   \n",
       "1  京港 金融合作 机遇 文字 快照 本报讯 记者 韩秉志 诗阳 第二十五届 北京 香港 经济 ...   \n",
       "2  青岛 崂山 链条 金融服务 助力 引育 人才 文字 快照 免费 拎包 入住 感觉 真爽 外地...   \n",
       "3  坚守 回馈 社会 光大银行 全面 推进 建设 联合国环境规划署 首次 提出 环境 社会 责任...   \n",
       "4  信创 加速 美国 技术 封锁 国内 政策 支持 本土 产业链 加速 铺进 关键 行业 核心 ...   \n",
       "\n",
       "                               filtered_fenci_result  \n",
       "0  数据库 以为 代表 外资 数据库 软件 中国 数据库 存储 计算 底层 硬件 之上 上层 应...  \n",
       "1  京港 机遇 文字 快照 记者 北京 香港 经济 合作 洽谈会 北京 香港 两地 洽谈会 融入...  \n",
       "2  青岛 金融服务 助力 人才 文字 快照 山东 青岛 工作 公司 人才 公寓 恒丰 理财 公司...  \n",
       "3  坚守 回馈 社会 光大银行 全面 推进 建设 首次 提出 环境 社会 责任 理念 倡导 关注...  \n",
       "4  信创 加速 美国 技术 国内 政策 支持 本土 产业链 加速 关键 行业 核心 领域 公司 ...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e47bf634",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList = list(data.fenci_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24491688",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(min_df = 1, stop_words = stopwords, analyzer = 'word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51e43dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_vec = count_vect.fit_transform(wordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48fdaa03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 2 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(words_vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5400b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1=pd.DataFrame(words_vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59df85d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3660)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_vec.toarray().shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "020f861f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "vectorized_df = pd.DataFrame()\n",
    "vectorizer = CountVectorizer(min_df = 1, stop_words = stopwords, analyzer = 'word')\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    text = list(data['text'])\n",
    "    vector = vectorizer.fit_transform(text)\n",
    "    vector_df = pd.DataFrame(vector.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    standardized_vector = scaler.fit_transform(vector_df)\n",
    "    vectorized_df = pd.concat([vectorized_df, pd.DataFrame(standardized_vector)], ignore_index=True)\n",
    "\n",
    "vectorized_df['date'] = data['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d01d77b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyterlab in d:\\anaconda\\lib\\site-packages (3.4.4)\n",
      "Requirement already satisfied: ipython in d:\\anaconda\\lib\\site-packages (from jupyterlab) (7.31.1)\n",
      "Requirement already satisfied: nbclassic in d:\\anaconda\\lib\\site-packages (from jupyterlab) (0.3.5)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\lib\\site-packages (from jupyterlab) (21.3)\n",
      "Requirement already satisfied: jupyter-core in d:\\anaconda\\lib\\site-packages (from jupyterlab) (4.11.1)\n",
      "Requirement already satisfied: jupyterlab-server~=2.10 in d:\\anaconda\\lib\\site-packages (from jupyterlab) (2.10.3)\n",
      "Requirement already satisfied: jinja2>=2.1 in d:\\anaconda\\lib\\site-packages (from jupyterlab) (2.11.3)\n",
      "Requirement already satisfied: jupyter-server~=1.16 in d:\\anaconda\\lib\\site-packages (from jupyterlab) (1.18.1)\n",
      "Requirement already satisfied: notebook<7 in d:\\anaconda\\lib\\site-packages (from jupyterlab) (6.4.12)\n",
      "Requirement already satisfied: tornado>=6.1.0 in d:\\anaconda\\lib\\site-packages (from jupyterlab) (6.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\anaconda\\lib\\site-packages (from jinja2>=2.1->jupyterlab) (2.0.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in d:\\anaconda\\lib\\site-packages (from jupyter-server~=1.16->jupyterlab) (7.3.4)\n",
      "Requirement already satisfied: websocket-client in d:\\anaconda\\lib\\site-packages (from jupyter-server~=1.16->jupyterlab) (0.58.0)\n",
      "Requirement already satisfied: prometheus-client in d:\\anaconda\\lib\\site-packages (from jupyter-server~=1.16->jupyterlab) (0.14.1)\n",
      "Requirement already satisfied: pywinpty in d:\\anaconda\\lib\\site-packages (from jupyter-server~=1.16->jupyterlab) (2.0.2)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in d:\\anaconda\\lib\\site-packages (from jupyter-server~=1.16->jupyterlab) (6.4.4)\n",
      "Requirement already satisfied: argon2-cffi in d:\\anaconda\\lib\\site-packages (from jupyter-server~=1.16->jupyterlab) (21.3.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in d:\\anaconda\\lib\\site-packages (from jupyter-server~=1.16->jupyterlab) (0.13.1)\n",
      "Requirement already satisfied: nbformat>=5.2.0 in d:\\anaconda\\lib\\site-packages (from jupyter-server~=1.16->jupyterlab) (5.5.0)\n",
      "Requirement already satisfied: Send2Trash in d:\\anaconda\\lib\\site-packages (from jupyter-server~=1.16->jupyterlab) (1.8.0)\n",
      "Requirement already satisfied: anyio<4,>=3.1.0 in d:\\anaconda\\lib\\site-packages (from jupyter-server~=1.16->jupyterlab) (3.5.0)\n",
      "Requirement already satisfied: traitlets>=5.1 in d:\\anaconda\\lib\\site-packages (from jupyter-server~=1.16->jupyterlab) (5.1.1)\n",
      "Requirement already satisfied: pyzmq>=17 in d:\\anaconda\\lib\\site-packages (from jupyter-server~=1.16->jupyterlab) (23.2.0)\n",
      "Requirement already satisfied: pywin32>=1.0 in d:\\anaconda\\lib\\site-packages (from jupyter-core->jupyterlab) (302)\n",
      "Requirement already satisfied: jsonschema>=3.0.1 in d:\\anaconda\\lib\\site-packages (from jupyterlab-server~=2.10->jupyterlab) (4.16.0)\n",
      "Requirement already satisfied: json5 in d:\\anaconda\\lib\\site-packages (from jupyterlab-server~=2.10->jupyterlab) (0.9.6)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from jupyterlab-server~=2.10->jupyterlab) (2.28.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in d:\\anaconda\\lib\\site-packages (from jupyterlab-server~=2.10->jupyterlab) (0.4)\n",
      "Requirement already satisfied: babel in d:\\anaconda\\lib\\site-packages (from jupyterlab-server~=2.10->jupyterlab) (2.9.1)\n",
      "Requirement already satisfied: ipykernel in d:\\anaconda\\lib\\site-packages (from notebook<7->jupyterlab) (6.15.2)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in d:\\anaconda\\lib\\site-packages (from notebook<7->jupyterlab) (1.5.5)\n",
      "Requirement already satisfied: ipython-genutils in d:\\anaconda\\lib\\site-packages (from notebook<7->jupyterlab) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in d:\\anaconda\\lib\\site-packages (from ipython->jupyterlab) (63.4.1)\n",
      "Requirement already satisfied: decorator in d:\\anaconda\\lib\\site-packages (from ipython->jupyterlab) (5.1.1)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from ipython->jupyterlab) (0.4.5)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\anaconda\\lib\\site-packages (from ipython->jupyterlab) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in d:\\anaconda\\lib\\site-packages (from ipython->jupyterlab) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\anaconda\\lib\\site-packages (from ipython->jupyterlab) (0.18.1)\n",
      "Requirement already satisfied: backcall in d:\\anaconda\\lib\\site-packages (from ipython->jupyterlab) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in d:\\anaconda\\lib\\site-packages (from ipython->jupyterlab) (3.0.20)\n",
      "Requirement already satisfied: pygments in d:\\anaconda\\lib\\site-packages (from ipython->jupyterlab) (2.11.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\anaconda\\lib\\site-packages (from packaging->jupyterlab) (3.0.9)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\anaconda\\lib\\site-packages (from anyio<4,>=3.1.0->jupyter-server~=1.16->jupyterlab) (3.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\anaconda\\lib\\site-packages (from anyio<4,>=3.1.0->jupyter-server~=1.16->jupyterlab) (1.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in d:\\anaconda\\lib\\site-packages (from jedi>=0.16->ipython->jupyterlab) (0.8.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in d:\\anaconda\\lib\\site-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.10->jupyterlab) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in d:\\anaconda\\lib\\site-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.10->jupyterlab) (0.18.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\lib\\site-packages (from jupyter-client>=6.1.12->jupyter-server~=1.16->jupyterlab) (2.8.2)\n",
      "Requirement already satisfied: bleach in d:\\anaconda\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in d:\\anaconda\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab) (0.7.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in d:\\anaconda\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab) (0.8.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in d:\\anaconda\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab) (0.1.2)\n",
      "Requirement already satisfied: testpath in d:\\anaconda\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab) (0.6.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in d:\\anaconda\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab) (1.5.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in d:\\anaconda\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab) (0.5.13)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab) (4.11.1)\n",
      "Requirement already satisfied: fastjsonschema in d:\\anaconda\\lib\\site-packages (from nbformat>=5.2.0->jupyter-server~=1.16->jupyterlab) (2.16.2)\n",
      "Requirement already satisfied: wcwidth in d:\\anaconda\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyterlab) (0.2.5)\n",
      "Requirement already satisfied: argon2-cffi-bindings in d:\\anaconda\\lib\\site-packages (from argon2-cffi->jupyter-server~=1.16->jupyterlab) (21.2.0)\n",
      "Requirement already satisfied: pytz>=2015.7 in d:\\anaconda\\lib\\site-packages (from babel->jupyterlab-server~=2.10->jupyterlab) (2022.1)\n",
      "Requirement already satisfied: debugpy>=1.0 in d:\\anaconda\\lib\\site-packages (from ipykernel->notebook<7->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: psutil in d:\\anaconda\\lib\\site-packages (from ipykernel->notebook<7->jupyterlab) (5.9.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->jupyterlab-server~=2.10->jupyterlab) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->jupyterlab-server~=2.10->jupyterlab) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\anaconda\\lib\\site-packages (from requests->jupyterlab-server~=2.10->jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: six in d:\\anaconda\\lib\\site-packages (from websocket-client->jupyter-server~=1.16->jupyterlab) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in d:\\anaconda\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.16->jupyterlab) (1.15.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab) (2.3.1)\n",
      "Requirement already satisfied: webencodings in d:\\anaconda\\lib\\site-packages (from bleach->nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab) (0.5.1)\n",
      "Requirement already satisfied: pycparser in d:\\anaconda\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.16->jupyterlab) (2.21)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bfe613d",
   "metadata": {},
   "source": [
    "# Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b36edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "613a640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"Human machine interface for lab abc computer applications\"\n",
    "text_corpus = [\n",
    "  \"Human machine interface for lab abc computer applications\",\n",
    "  \"A survey of user opinion of computer system response time\",\n",
    "  \"The EPS user interface management system\",\n",
    "  \"System and human system engineering testing of EPS\",\n",
    "  \"Relation of user perceived response time to error measurement\",\n",
    "  \"The generation of random binary unordered trees\",\n",
    "  \"The intersection graph of paths in trees\",\n",
    "  \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "  \"Graph minors A survey\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b63e2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'interface', 'computer'],\n",
      " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
      " ['eps', 'user', 'interface', 'system'],\n",
      " ['system', 'human', 'system', 'eps'],\n",
      " ['user', 'response', 'time'],\n",
      " ['trees'],\n",
      " ['graph', 'trees'],\n",
      " ['graph', 'minors', 'trees'],\n",
      " ['graph', 'minors', 'survey']]\n"
     ]
    }
   ],
   "source": [
    "# 创建停用词列表\n",
    "stoplist = set('for a of the and to in'.split(' '))\n",
    "# 小写化，空格分词，使用停用词\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "         for document in text_corpus]\n",
    "\n",
    "# 计算词频\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "#仅保留出现超过一次的单词\n",
    "processed_corpus = [[token for token in text if frequency[token] > 1] for text in texts]\n",
    "pprint.pprint(processed_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be94e9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "dictionary = corpora.Dictionary(processed_corpus)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a2c33a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'computer': 0,\n",
      " 'eps': 8,\n",
      " 'graph': 10,\n",
      " 'human': 1,\n",
      " 'interface': 2,\n",
      " 'minors': 11,\n",
      " 'response': 3,\n",
      " 'survey': 4,\n",
      " 'system': 5,\n",
      " 'time': 6,\n",
      " 'trees': 9,\n",
      " 'user': 7}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24e1d4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1)]\n"
     ]
    }
   ],
   "source": [
    "new_doc = \"Human computer interaction\"\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
    "print(new_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e17cdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1)],\n",
      " [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
      " [(2, 1), (5, 1), (7, 1), (8, 1)],\n",
      " [(1, 1), (5, 2), (8, 1)],\n",
      " [(3, 1), (6, 1), (7, 1)],\n",
      " [(9, 1)],\n",
      " [(9, 1), (10, 1)],\n",
      " [(9, 1), (10, 1), (11, 1)],\n",
      " [(4, 1), (10, 1), (11, 1)]]\n"
     ]
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(text) for text in processed_corpus]\n",
    "pprint.pprint(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d3d0028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5, 0.5898341626740045), (11, 0.8075244024440723)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "\n",
    "# 训练模型，输入是文档稀疏表达的元祖二维列表。\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "\n",
    "# 转化 \"system minors\" 字符串\n",
    "words = \"system minors\".lower().split()\n",
    "print(tfidf[dictionary.doc2bow(words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d4b00ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import similarities\n",
    "# 相似性\n",
    "index = similarities.SparseMatrixSimilarity(tfidf[bow_corpus], num_features=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6775b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_document = 'system engineering'.split()\n",
    "query_bow = dictionary.doc2bow(query_document)\n",
    "sims = index[tfidf[query_bow]]\n",
    "print(list(enumerate(sims)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
