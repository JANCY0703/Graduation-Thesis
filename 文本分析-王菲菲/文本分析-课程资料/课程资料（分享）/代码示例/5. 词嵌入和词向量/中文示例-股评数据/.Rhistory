library(knitr)
library(rmdformats)
library(word2vec)
library(jiebaR)
options(max.print="1e5")
opts_chunk$set(echo=TRUE,
cache=FALSE,
prompt=FALSE,
tidy=TRUE,
comment=NA,
message=FALSE,
warning=FALSE)
opts_knit$set(width=75)
colors <- c('#f3a683',
'#f7d794',
'#778beb',
'#e77f67',
'#cf6a87',
'#f19066',
'#f5cd79',
'#546de5',
'#e15f41',
'#c44569')
data.Chinese <- read.csv2("./labeled-corpus-sampled.csv", header = TRUE, sep = ",", encoding = "UTF-8")
texts <- data.Chinese$text
texts
class(texts)
dim(texts)
ds.txt"
stoppath <- "./cn_stopwords.txt"  # 设置停用词所在目录
stoppath <- "./cn_stopwords.txt"  # 设置停用词所在目录
texts <- gsub("[0-9]","",texts)   # 将数字去除
cutter = worker('tag', bylines = TRUE, stop_word = stoppath, symbol = F)
res = cutter[texts]                # 进行分词,这步会比较慢
res[[1]]
strs <- rep("", length(res))
strs
length(res[[1]])
res[[1]][1]
strs <- rep("", length(res))
for(i in 1:length(res)) {
str <- ""
for (j in 1:length(res[[i]])) {
str <- paste(str, res[[i]][j], sep = " ")
}
strs[i] <- str
}
strs
model <- word2vec(strs, type = "skip-gram", dim = 50, encoding = "UTF-8")
predict(model, "涨", top_n = 10)
predict(model, "涨", top_n = 10)
model <- word2vec(strs, type = "skip-gram", dim = 50, encoding = "UTF-8")
predict(model, "涨", top_n = 10)
model <- word2vec(strs, type = "cbow", dim = 50, encoding = "UTF-8")
predict(model, "涨", top_n = 10)
