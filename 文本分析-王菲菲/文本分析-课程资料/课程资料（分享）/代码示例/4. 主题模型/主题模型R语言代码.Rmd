---
title: "主题模型R语言代码"
date: ""
output:
  rmdformats::readthedown:
    highlight: kate
    number_sections: true
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
# 加载相关的包
library(rio)
library(reshape)
library(quanteda)
library(reshape2)
library(ggplot2)
library(quanteda.textstats)
library(textstem)
# library(qdap)
library(jiebaR)
library(wordcloud2)
library(RColorBrewer)
library(knitr)
library(rmdformats)
library(plyr)
library(tidyverse)
library(magrittr)
library(dplyr)
library(tidyr)
library(lubridate)
library(textclean)
library(tm)
library(SnowballC)
library(tidytext)
library(topicmodels)
library(textmineR)
library(wordcloud)
library(ggwordcloud)
library(ldatuning)
library(DT)
library(data.table)
library(LDAvis)
library(stringi)
library(servr)
library(readxl)
library(showtextdb)
library(showtext)
library(scales)
library(latex2exp)
library(stringr)
font_add(family = "songti", 
         regular = "C:/Windows/Fonts/simsun.ttc")
showtext_auto(enable=T)
opts_chunk$set(message=FALSE,
               warning=FALSE)
```

# 读取数据，划分高评分与低评分评论

```{r}
# 读取movie reviews的数据
movie <- read_xlsx("./movie reviews.xlsx")
# 筛选出电影冰雪奇缘的数据
movie_fro <- movie[which(movie$`film name`=="Frozen II"),]

# 根据评分是否超过6分划分评论
# 高评分评论共545条
data_1 <- movie_fro %>% filter(rating >=6)

# 低评分评论共148条
data_2 <- movie_fro %>% filter(rating <6)

# 查看rating的频数分布表
table(movie_fro$rating)
```



# 预处理
```{r}
# 使用高评论数据data_1中的review列创建corpus
corpus1 <- corpus(data_1, text_field = "review")
# 分词将评论语句转化为tokens，进行预处理,去掉数字，去掉标点，去掉链接
tokens1 <- quanteda::tokens(corpus1, remove_numbers=TRUE, remove_punct=TRUE, remove_url=TRUE)
# 将含有.token用.分割开，并去掉.
tokens1 <- tokens_split(tokens1, separator = ".", remove_separator = TRUE)
# 全部转化为小写
tokens1 <- tokens_tolower(tokens1) 

# 去除停用词
tokens1 <- tokens_remove(tokens1, stopwords::stopwords("en", "smart"))

# 构建dfm
dfm1 <- dfm(tokens1, tolower = TRUE) %>%
  dfm_wordstem() # dfm_wordstem()进行词干化

# 保留词频在2-400之间的词语
dfm_trim1 <- dfm_trim(dfm1, min_termfreq = 2, max_docfreq = 400)

# 将dfm转换为dtm
dtm1 <- convert(dfm_trim1, to = "topicmodels")

```


# 确定主题数

```{r}
# n_topics是一系列备选的主题数
n_topics <- seq(2, 15, by = 2)

# 生成一系列主题数不同的LDA模型
lda_compare1 <- map(n_topics, LDA, x = dfm_trim1)
# 或许不同主题数下的困惑度的值，并形成dataframe的格式
get_perplexity <- data.frame(k = n_topics,
  perplex = map_dbl(lda_compare1, perplexity))

# 绘制困惑度随主题数的变化曲线
# 计算各个lda模型的困惑度，将数据传递给ggplot
plot <- ggplot(aes(k, perplex), data = get_perplexity) + # 设置x,y轴分别为k和perplex
  geom_point() +            # 在图形中画点
  geom_line() +              # 画线
  theme_bw()+
  labs(# title = "评估确定LDA的主题数", # 添加标题
  x = "主题数",           # 添加x轴标签
  y = "困惑度（Perplexity）", family="songti")+# 添加y轴标签
  theme(axis.title.x = element_text(size = 15),
        axis.title.y = element_text(size = 15),
        text=element_text(size=16,  family="songti"),
        panel.grid.major=element_line(colour=NA),
        panel.background = element_rect(fill = "transparent",colour = NA),
        plot.background = element_rect(fill = "transparent",colour = NA),
        panel.grid.minor = element_blank())

plot
ggsave('./plots/LDA主题数与困惑度折线图.pdf', plot,
       width=14, height=12, dpi=1000, units="cm")

```

# 选六个主题，构建LDA主题模型

尝试了六至十个主题后，由于选择六个主题时的结果更易于解释，因此这里选择六个主题。

```{r}
# k为主题数，使用Gibbs采样进行估计，因此需要设定随机数种子，设置超参数alpha；
lda1 <- LDA(dtm1, k = 6, method = "Gibbs", control = list(alpha = 0.1, seed = 12))
```

# 主题的关键词

```{r}
# 查看每个主题的前20个关键词
# terms(lda1, 20) 
kable(terms(lda1, 20), format = "html")
# write.csv(terms(lda1, 20), "D:/data/lda_terms_1.csv") # 将获得的主题关键词写入csv文件
```

根据以上关键词总结六个主题如下：

主题1：*Frozen*系列

主题2：主题曲

主题3：剧情

主题4：与女儿/姐妹/家人观看

主题5：正面评价

主题6：角色


注：Idina Menzel是Frozen的主角Elsa的配音者，演唱了Frozen系列的主题曲*Let It Go*, *Into the Unknown*, *Show Yourself*等。



# 主题-词语分布(beta)

```{r}
# 提取主题词语分布(beta)
topics1 <- tidy(lda1, matrix="beta")
# 分别指定名称给六个topic
topics1$topic[topics1$topic=="1"] <- c("Frozen系列")
topics1$topic[topics1$topic=="2"] <- c("主题曲")
topics1$topic[topics1$topic=="3"] <- c("剧情")
topics1$topic[topics1$topic=="4"] <- c("与女儿/姐妹/家人观看")
topics1$topic[topics1$topic=="5"] <- c("正面评价")
topics1$topic[topics1$topic=="6"] <- c("角色")
# 查看前20个主题-词语分布
head(topics1, 20)
```




```{r}
# 提取每个主题中概率值最大的前十个值，并且按概率值降序排序
top_terms1 <- topics1 %>% # 将topics1的数据使用管道函数传给group_by
  group_by(topic) %>%  # 按照主题进行分组汇总
  top_n(10, beta) %>% # 每个主题保留前10个词
  ungroup() %>%   # 取消分组
  arrange(topic, -beta) #对每个主题的关键词按照相应概率值降序排列

head(top_terms1,20) # 查看前20个数据
```

## 每个主题的关键词的可视化

### 条形图


```{r}
# 绘制每个主题和提取的10个出现概率值最大的主题词的条形图
plot_terms <- top_terms1 %>%
  mutate(term = reorder(term, beta)) %>% # term按照beta数值降序排列
  ggplot(aes(term, beta, fill = factor(topic))) + # 设置绘图的变量为term和beta，不同的主题设置不同的颜色
  geom_col(show.legend = FALSE) + # 设置图例不显示
  facet_wrap(~ topic, scales = "free") + # 按照主题分成不同的子图，通过参数scales来控制面板位置标度的固定和自由，x 和 y 的标度都可变
  coord_flip()+ # 把x轴和y轴互换，从垂直条形图变为水平条形图
  theme_bw()

plot_terms
ggsave('./plots/各主题关键词及其出现概率.pdf', plot_terms,
       width=20, height=12, dpi=1000, units="cm")
```

### 词云图


```{r}
# 获得lda模型的主题词语分布和文档主题分布
tmResult1 <- modeltools::posterior(lda1, )
# 画出topic6关键词的词云图，topicToViz是想要画词云图的主题序号
topicToViz <- 6
# 选出主题的前50个关键词及其概率
top50terms <- sort(tmResult1$terms[topicToViz,], decreasing=TRUE)[1:50]
# 提取前50个关键词
words <- names(top50terms)
# 提取前50个关键词的概率
probabilities <- sort(tmResult1$terms[topicToViz,], decreasing=TRUE)[1:50]
# 设置随机种子
set.seed(1234)
# 绘制词云图，相应的概率值作为词语的大小,设置字体大小为1
wordcloud2(data.frame(words, probabilities), shuffle = FALSE, size = 1)
```


# 文档-主题分布(gamma)

```{r}
# 提取文档-主题分布(gamma)
topics_doc1 <- tidy(lda1, matrix="gamma")
```

```{r}
# 将文档名由"text1","text2","text3",...命名为1,2,3,...的形式，从而便于文档的排序
# 去掉topics_doc1$document列中的“text”,即将“text1”变为“1”
topics_doc1$document <- gsub("text", "", topics_doc1$document)
# 将字符化为数字，即将“1”变为1
topics_doc1$document <- as.numeric(topics_doc1$document)

# 文档-主题分布的概率矩阵
topics_doc_sp1 <- tidyr::spread(topics_doc1, topic, gamma)
topics_doc_sp1
```



## 每个文档的主题的可视化

```{r}
# 以前5条评论为例
exampleIds <- c(1:5)
N <- length(exampleIds)
# 去掉第一列，第一列为文档名称
topicProportionExamples <- topics_doc_sp1[exampleIds,-1] 
# 修改列名为下面的topicNames
topicNames <- c("Frozen系列", "主题曲", "剧情", "与女儿/姐妹/家人观看", "正面评价", "角色")
colnames(topicProportionExamples) <- topicNames

# 改变数据的排列方式分为三列document,topic,value
vizDataFrame <- melt(cbind(data.frame(topicProportionExamples), document = factor(1:N)), variable.name = "topic", id.vars = "document")  

# 绘制前5条文档的文档-主题分布的条形图
# 设置绘图的变量为topic和value，不同的文档用不同颜色填充，设置纵轴标签为proportion

plot_topic <- ggplot(data = vizDataFrame, 
                     aes(topic, value, fill = document), ylab = "proportion") + 
  geom_bar(stat="identity") + # 绘制条形图，identity表示条形的高度是变量的值
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +  # x轴刻度字体旋转90度，设置水平距离为1
  coord_flip() + # x轴和y轴互换
  facet_wrap(~ document, ncol = N) # 按照文档分为不同子图，子图排为5列

plot_topic
ggsave('./plots/前5条文档的文档-主题分布图.pdf', plot_topic,
       width=20, height=12, dpi=1000, units="cm")
```

这里列出第一至五条文档预处理之后的tokens，以便与上图对照。

```{r}
#第一条
tokens1[[1]]
#fwrite(as.list(tokens1[[1]]), "D:/data/reviews1_1.txt")

#第二条
tokens1[[2]]
#fwrite(as.list(tokens1[[2]]), "D:/data/reviews1_2.txt")

#第三条
tokens1[[3]]
#fwrite(as.list(tokens1[[3]]), "D:/data/reviews1_3.txt")

#第四条
tokens1[[4]]
#fwrite(as.list(tokens1[[4]]), "D:/data/reviews1_4.txt")

#第五条
tokens1[[5]]
#fwrite(as.list(tokens1[[5]]), "D:/data/reviews1_5.txt")
```



# 使用LDAvis包进行可视化

```{r}
# 获得主题-词语矩阵phi
phi <- modeltools::posterior(lda1)$terms %>% as.matrix
# 获得文档主题矩阵theta
theta <- modeltools::posterior(lda1)$topics %>% as.matrix
# 单词
vocab <- colnames(phi)
# 每篇文章单词的个数
doc_length <- ntoken(corpus1[rownames(dtm1)])

#使用tm包中的VCorpus创建corpus
corpus_tm1 <- VCorpus(VectorSource(data_1$review))

# 获得每个单词及其频数
freq1 <- (sort(apply(dtm1,2,sum), decreasing =T))
# 提取freq1中所有的频数
temp_frequency <- as.integer(freq1) 

#使用前面获得的数据，转化为json对象
json_lda <- LDAvis::createJSON(phi = phi, theta = theta,
                            vocab = vocab,
                            doc.length = doc_length,
                            term.frequency = temp_frequency)

# 将可视化结果保存在out.dir路径下，在浏览器中查看lda的可视化结果
serVis(json_lda, out.dir = 'LDAvis_R',open.browser = FALSE) # 设为FALSE可以将rmarkdown正常输出为html，但是无法看到图像
#serVis(json_lda, out.dir = 'vis',open.browser = TRUE)
#将open.browser设为TRUE时运行之后会出现下面的语句：
#Serving the directory E:\研\LDA代码\6.主题模型\vis at http://127.0.0.1:4321,在浏览器打开网址即可看到可视化的交互图像。
```


<link rel="stylesheet" type="text/css" href="LDAvis_R/lda.css">
<script src="LDAvis_R/d3.v3.js"></script>
<script src="LDAvis_R/ldavis.js"></script>

<iframe width="1200" height="1500" src="LDAvis_R/index.html" frameborder="0"></iframe>


