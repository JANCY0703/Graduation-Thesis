---
title: "有监督文本分类"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
    number_sections: true
---


```{r setup, include=FALSE}
library(knitr)
library(rmdformats)
library(ggplot2)

## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
	             cache=FALSE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
```

# 数据预处理

## 数据读入
```{r data_readin}
library(openxlsx)
# 读取数据
data_all <- read.xlsx("./movie reviews.xlsx")
data_all <- na.omit(data_all)
```

```{r echo=FALSE, include=FALSE}
# 查看各类电影评论数
library(dplyr)
count <- data_all %>%
  select(film_name = `film.name`) %>%
  group_by(film_name) %>%
  summarize(n = n())
```

## 给评论消极/积极的标签

```{r data_preprocessing}
# 选择复联4（Avengers: Endgame）这部电影的评论数据
data_avengers <- data_all[which(data_all$`film.name`=="Avengers: Endgame"),]
len <- length(data_avengers[,1])

# 提取出数据的“评论”和“评分”这两列
review <- data_avengers['review']
rating <- data_avengers['rating']

# 将评分1-5作为消极评论，用0表示，6-10分作为积极评论，用1表示
rate <- rep(0, len)
rate[which(rating > 5)] <- 1

# 建立数据框
review_data <- cbind(review,rate)
colnames(review_data) <- c("review","rate")
```

## 建立语料库

```{r corpus}
library(tm)
# 创建语料库
review_corpus <- VCorpus(VectorSource(review_data$review))

# 清洗文本数据
review_corpus_clean <- review_corpus %>% 
  tm_map(content_transformer(tolower)) %>% # 将字母转换为小写
  tm_map(removeNumbers) %>% # 去除文本中的数字
  tm_map(removeWords, stopwords()) %>% # 去除停用词
  tm_map(removePunctuation) %>% # 去除标点符号
  tm_map(stemDocument) %>% # 提取单词的词干
  tm_map(stripWhitespace) # 删除额外的空白

# 将文本文档拆分成词语, 创建文档——单词矩阵 
control <- list(removePunctuation=T,
                minDocFreq=5,
                wordLengths = c(1, Inf),
                weighting = weightTfIdf)
review_dtm <- DocumentTermMatrix(review_corpus_clean,control)
removed <- removeSparseTerms(review_dtm, 0.95)

# 转化为矩阵
mat <- as.matrix(removed)
```

## 划分测试集/训练集

```{r train & test}
# 取0.7的数据做训练集,取0.3的数据做测试集
set.seed(1)
train_prop <- 0.7
n.train <- round(len*train_prop)
n.test <- len - n.train
index <- sample(1:len, n.train)
review_train <- mat[index,]
review_test <- mat[-index,]
rate_train <- review_data[index,2]
rate_test <- review_data[-index,2]

# 转为数据框格式
train <- data.frame(cbind(rate_train, review_train))
test <- data.frame(cbind(rate_test, review_test))
train$rate_train <- factor(train$rate_train)
test$rate_test <- factor(test$rate_test)
```

# 逻辑回归模型

## 拟合模型

```{r logit}
# 训练模型
logistic_classifier <- glm(rate_train~.,
                           data=train,
                           family = binomial(link=logit))
# 对测试集中的样本进行预测
logistic_pred <- predict(logistic_classifier,
                         test,
                         type="response")

# 计算0/1预测结果，概率大于0.5为积极评论
yhat_logistic <- rep(0,length(logistic_pred))
yhat_logistic[logistic_pred > 0.5] <- 1

# 混淆矩阵
table(rate_test, yhat_logistic)
```

## 绘制ROC曲线

```{r logit roc}
library(pROC)
# 使用roc函数获取相关值
logistic_roc <- roc(rate_test, 
                    logistic_pred, 
                    plot=FALSE)

# 绘制图形
logistic_res <- data.frame(1-logistic_roc$specificities, logistic_roc$sensitivities)
colnames(logistic_res) <- c("FPR", "TPR")
plot_logistic <- ggplot(data = logistic_res) +
  geom_line(aes(x = FPR, y = TPR, color = "逻辑回归")) +
  theme_bw() +
  geom_abline(aes(slope = 1, intercept = 0), color = I("gray")) +
  geom_text(aes(x = 0.6, y = 0.4, label = "AUC=0.857")) +
  scale_color_discrete(guide = NULL)
plot_logistic
```

# 朴素贝叶斯模型

## 拟合模型

```{r naive bayes}
library(e1071)
# 训练模型, 拉普拉斯估计参数默认为 0
NB_classifier <- naiveBayes(rate_train~.,data=train)
summary(NB_classifier)

# 对测试集中的样本进行预测，这里给出的是0/1预测
nb_pred <- predict(NB_classifier, review_test)
# 指定参数type="raw"，给出的是具体的预测概率
nb_prob <- predict(NB_classifier, review_test, type="raw")
# 预测为1的概率
yhat_nb <- nb_prob[,2] 

# 混淆矩阵
table(rate_test, nb_pred)
```

## 绘制ROC曲线

```{r naive bayes roc}
# 使用roc函数获取相关值
nb_roc <- roc(rate_test, yhat_nb)

# 绘制图形
nb_res <- data.frame(1-nb_roc$specificities, nb_roc$sensitivities)
colnames(nb_res) <- c("FPR", "TPR")
plot_nb <- ggplot(data = nb_res) +
  geom_line(aes(x = FPR, y = TPR, color = "朴素贝叶斯")) +
  theme_bw() +
  geom_abline(aes(slope = 1, intercept = 0), color = I("gray")) +
  geom_text(aes(x = 0.6, y = 0.4, label = "AUC=0.774")) +
  scale_color_discrete(guide = NULL)
plot_nb
```


# 决策树模型

## 拟合模型

```{r tree}
library(rpart)
# 调用函数进行训练
TREE_classifier <- rpart(rate_train~., 
                         data=train, 
                         control=rpart.control(minsplit=2, cp=0))

# 对测试集中的样本进行预测
Tree_prob <- predict(TREE_classifier, newdata=test)
Tree_pred <- rep(0, n.test)
yhat_tree <- Tree_prob[,2]
Tree_pred[which(yhat_tree > 0.5)] <- 1

# 混淆矩阵
table(rate_test,Tree_pred)
```


## 绘制ROC曲线

```{r tree roc}
# 使用roc函数获取相关值
tree_roc <- roc(rate_test, yhat_tree)

# 绘制图形
tree_res <- data.frame(1-tree_roc$specificities, tree_roc$sensitivities)
colnames(tree_res) <- c("FPR", "TPR")
plot_tree <- ggplot(data = tree_res) +
  geom_line(aes(x = FPR, y = TPR, color = "决策树")) +
  theme_bw() +
  geom_abline(aes(slope = 1, intercept = 0), color = I("gray")) +
  geom_text(aes(x = 0.6, y = 0.4, label = "AUC=0.639")) +
  scale_color_discrete(guide = NULL)
plot_tree
```

# 随机森林

```{r random forest}
library(ranger)
RF_classifier <- ranger(rate_train~.,
                        data = train, 
                        num.trees = 500)
RF_pred <- predict(RF_classifier, data=test)

# 混淆矩阵
table(rate_test,RF_pred$predictions)
```


# 支持向量机

```{r SVM}
svm_classifier <- svm(rate_train~.,
                      data = train,
                      probability = TRUE)
svm_pred <- predict(svm_classifier,newdata=test)

# 混淆矩阵
table(rate_test,svm_pred)
```


```{r SVM roc}
svm_res <- predict(svm_classifier,
                   review_test,
                   probability = TRUE)
yhat_svm <- attr(svm_res,"probabilities")[,1]

# 使用roc函数获取相关值
svm_roc <- roc(rate_test, yhat_svm)

# 绘制图形
svm_res <- data.frame(1-svm_roc$specificities, svm_roc$sensitivities)
colnames(svm_res) <- c("FPR", "TPR")
plot_svm <- ggplot(data = svm_res) +
  geom_line(aes(x = FPR, y = TPR, color = "支持向量机")) +
  theme_bw() +
  geom_abline(aes(slope = 1, intercept = 0), color = I("gray")) +
  geom_text(aes(x = 0.6, y = 0.4, label = "AUC=0.829")) +
  scale_color_discrete(guide = NULL)
plot_svm
```


# 神经网络

```{r mlp}
library(RSNNS)
# 调用mlp()进行前馈神经网络模型训练
mlp_classifier <- mlp(train[,-1], 
                      rate_train, 
                      maxit=1000,
                      inputsTest = test[,-1],
                      targetsTest = rate_test)

mlp_pred <- predict(mlp_classifier,test[,-1])

yhat <- rep(0,length(mlp_pred))
yhat[mlp_pred>0.5] <- 1
#混淆矩阵
table(rate_test,yhat)
```


```{r mlp roc}
mlp_res <- predict(mlp_classifier,
                   review_test,
                   probability = TRUE)
yhat_mlp <- attr(mlp_res,"probabilities")[,1]

# 使用roc函数获取相关值
mlp_roc <- roc(rate_test, mlp_pred)

# 绘制图形
mlp_res <- data.frame(1-mlp_roc$specificities, mlp_roc$sensitivities)
colnames(mlp_res) <- c("FPR", "TPR")
plot_mlp <- ggplot(data = mlp_res) +
  geom_line(aes(x = FPR, y = TPR, color = "神经网络")) +
  theme_bw() +
  geom_abline(aes(slope = 1, intercept = 0), color = I("gray")) +
  geom_text(aes(x = 0.6, y = 0.4, label = "AUC=0.821")) +
  scale_color_discrete(guide = NULL)
plot_mlp
```


# 模型对比
```{r comparison}
plot_comparison <- ggplot() +
  geom_line(aes(x = FPR, y = TPR, color = "逻辑回归, AUC=0.857"), 
            data = logistic_res) +
  geom_line(aes(x = FPR, y = TPR, color = "朴素贝叶斯, AUC=0.774"),
            data = nb_res) +
  geom_line(aes(x = FPR, y = TPR, color = "决策树, AUC=0.639"), 
            data = tree_res) +
  geom_line(aes(x = FPR, y = TPR, color = "支持向量机, AUC=0.829"),
            data = svm_res) +
  geom_line(aes(x = FPR, y = TPR, color = "神经网络, AUC=0.821"),
            data = mlp_res) +
  theme_bw() +
  theme(legend.justification = c(1,0), legend.position = c(1,0)) +
  geom_abline(aes(slope = 1, intercept = 0), color = I("gray")) +
  guides(color = guide_legend(title = NULL))
plot_comparison
```

