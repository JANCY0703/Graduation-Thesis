---
title: "中文文本有监督分类"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
    self_contained: true
    code_folding: show
    toc: 1
    number_sections: true
---

```{r setup, include=FALSE}
library(knitr)
library(dplyr)


## Global options
options(max.print="1e5")
opts_chunk$set(echo=TRUE,
	             cache=FALSE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)

opts_knit$set(width=75)
```


# 数据预处理

## 数据读入
```{r}
data <- read.csv2("./labeled-corpus-sampled.csv", header = TRUE, sep = ",", encoding = "UTF-8")
data$label = as.numeric(data$label == "1.0")
```

## 建立语料库
```{r}
library(jiebaR)
library(keras)
library(tensorflow)
# 中文分词
stoppath <- "./cn_stopwords.txt"  # 设置停用词所在目录
wk = worker(stop_word = stoppath)
data <- data %>% mutate(text_process = sapply(text, function(x) paste(wk[x], collapse = " ")))

# 文本向量化，构建文本-词矩阵，这里使用tf-idf方法
## 需要设置max_tokens，系统会根据前max_tokens个词频最高的词语来计算
text_vectorization <- layer_text_vectorization(
  max_tokens = 200,
  output_mode = "tf_idf",
)

text_vectorization %>% adapt(data$text_process)
vocabulary <- get_vocabulary(text_vectorization)

mat = as.matrix(text_vectorization(matrix(data$text_process, ncol = 1)))
colnames(mat) <- vocabulary
```

## 划分训练集/测试集
```{r}
# 取70%的数据做训练集,30%的数据做测试集
set.seed(1)
train_prop <- 0.7
n <- length(data[, 1])
n.train <- round(n * train_prop)
n.test <- n - n.train
index <- sample(1:n, n.train)
text_train <- mat[index, ]
text_test <- mat[-index, ]
label_train <- data[index, 1]
label_test <- data[-index, 1]

# 转为数据框格式
train <- data.frame(cbind(label_train, text_train))
test <- data.frame(cbind(label_test, text_test))
train$label_train <- factor(train$label_train)
test$label_test <- factor(test$label_test)
```



# 逻辑回归模型
## 拟合模型
```{r}
# 训练模型
logistic_classifier <- glm(label_train ~ ., data = train, family = binomial(link = logit))
# 对测试集中的样本进行预测
logistic_pred <- predict(logistic_classifier, test, type = "response")

# 计算0/1预测结果，概率大于0.5为积极评论
yhat_logistic <- rep(0, length(logistic_pred))
yhat_logistic[logistic_pred > 0.5] <- 1

# 混淆矩阵
table(label_test, yhat_logistic)
```

## 绘制ROC曲线
```{r}
library(pROC)
library(ggplot2)
# 使用roc函数获取相关值
logistic_roc <- roc(label_test, logistic_pred, plot = FALSE)

# 绘制图形
logistic_res <- data.frame(1 - logistic_roc$specificities, logistic_roc$sensitivities)
colnames(logistic_res) <- c("FPR", "TPR")
plot_logistic <- ggplot(data = logistic_res) + geom_line(aes(x = FPR, y = TPR, color = "逻辑回归")) +
    theme_bw() + geom_abline(aes(slope = 1, intercept = 0), color = I("gray")) +
    geom_text(aes(x = 0.6, y = 0.4, label = paste("AUC=",as.character(round(logistic_roc$auc[1], 2))))) + scale_color_discrete(guide = NULL)
plot_logistic
```


# 朴素贝叶斯模型
## 拟合模型
```{r}
library(e1071)
# 训练模型, 拉普拉斯估计参数默认为 0
NB_classifier <- naiveBayes(label_train ~ ., data = train)
summary(NB_classifier)

# 对测试集中的样本进行预测，这里给出的是0/1预测
nb_pred <- predict(NB_classifier, text_test)
# 指定参数type='raw'，给出的是具体的预测概率
nb_prob <- predict(NB_classifier, text_test, type = "raw")
# 预测为1的概率
yhat_nb <- nb_prob[, 2]

# 混淆矩阵
table(label_test, nb_pred)
```

## 绘制ROC曲线
```{r}
# 使用roc函数获取相关值
nb_roc <- roc(label_test, yhat_nb)

# 绘制图形
nb_res <- data.frame(1 - nb_roc$specificities, nb_roc$sensitivities)
colnames(nb_res) <- c("FPR", "TPR")
plot_nb <- ggplot(data = nb_res) + geom_line(aes(x = FPR, y = TPR, color = "朴素贝叶斯")) +
    theme_bw() + geom_abline(aes(slope = 1, intercept = 0), color = I("gray")) +
    geom_text(aes(x = 0.6, y = 0.4, label = paste("AUC=",as.character(round(nb_roc$auc[1], 2))))) + scale_color_discrete(guide = NULL)
plot_nb
```

# 决策树模型
## 拟合模型
```{r}
library(rpart)
# 调用函数进行训练
TREE_classifier <- rpart(label_train ~ ., data = train, control = rpart.control(minsplit = 2,
    cp = 0))

# 对测试集中的样本进行预测
Tree_prob <- predict(TREE_classifier, newdata = test)
Tree_pred <- rep(0, n.test)
yhat_tree <- Tree_prob[, 2]
Tree_pred[which(yhat_tree > 0.5)] <- 1

# 混淆矩阵
table(label_test, Tree_pred)
```

## 绘制ROC曲线
```{r}
# 使用roc函数获取相关值
tree_roc <- roc(label_test, yhat_tree)

# 绘制图形
tree_res <- data.frame(1 - tree_roc$specificities, tree_roc$sensitivities)
colnames(tree_res) <- c("FPR", "TPR")
plot_tree <- ggplot(data = tree_res) + geom_line(aes(x = FPR, y = TPR, color = "决策树")) +
    theme_bw() + geom_abline(aes(slope = 1, intercept = 0), color = I("gray")) +
    geom_text(aes(x = 0.6, y = 0.4, label = paste("AUC=",as.character(round(tree_roc$auc[1], 2))))) + scale_color_discrete(guide = NULL)
plot_tree
```

# 随机森林
```{r}
library(ranger)
RF_classifier <- ranger(label_train ~ ., data = train, num.trees = 500)
RF_pred <- predict(RF_classifier, data = test)

# 混淆矩阵
table(label_test, RF_pred$predictions)
```

# 支持向量机
## 拟合模型
```{r}
svm_classifier <- svm(label_train ~ ., data = train, probability = TRUE)
svm_pred <- predict(svm_classifier, newdata = test)

# 混淆矩阵
table(label_test, svm_pred)
```

## 绘制ROC曲线
```{r}
svm_res <- predict(svm_classifier, test[,-1], probability = TRUE)
yhat_svm <- attr(svm_res, "probabilities")[, 1]

# 使用roc函数获取相关值
svm_roc <- roc(label_test, yhat_svm)

# 绘制图形
svm_res <- data.frame(1 - svm_roc$specificities, svm_roc$sensitivities)
colnames(svm_res) <- c("FPR", "TPR")
plot_svm <- ggplot(data = svm_res) + geom_line(aes(x = FPR, y = TPR, color = "支持向量机")) +
    theme_bw() + geom_abline(aes(slope = 1, intercept = 0), color = I("gray")) +
    geom_text(aes(x = 0.6, y = 0.4, label = paste("AUC=",as.character(round(svm_roc$auc[1], 2))))) + scale_color_discrete(guide = NULL)
plot_svm
```

# 神经网络
## 模型拟合
```{r}
library(RSNNS)
# 调用mlp()进行前馈神经网络模型训练
mlp_classifier <- mlp(train[, -1], label_train, maxit = 1000, inputsTest = test[, -1], targetsTest = label_test)

mlp_pred <- predict(mlp_classifier, test[, -1])

yhat <- rep(0, length(mlp_pred))
yhat[mlp_pred > 0.5] <- 1
# 混淆矩阵
table(label_test, yhat)
```

## 绘制ROC曲线
```{r}
mlp_res <- predict(mlp_classifier, text_test, probability = TRUE)
yhat_mlp <- attr(mlp_res, "probabilities")[, 1]

# 使用roc函数获取相关值
mlp_roc <- roc(label_test, mlp_pred)

# 绘制图形
mlp_res <- data.frame(1 - mlp_roc$specificities, mlp_roc$sensitivities)
colnames(mlp_res) <- c("FPR", "TPR")
plot_mlp <- ggplot(data = mlp_res) + geom_line(aes(x = FPR, y = TPR, color = "神经网络")) +
    theme_bw() + geom_abline(aes(slope = 1, intercept = 0), color = I("gray")) +
    geom_text(aes(x = 0.6, y = 0.4, label = paste("AUC=",as.character(round(mlp_roc$auc[1], 2))))) + scale_color_discrete(guide = NULL)
plot_mlp
```

# 模型对比
```{r}
plot_comparison <- ggplot() + 
  geom_line(aes(x = FPR, y = TPR, color = paste("逻辑回归：","AUC=",as.character(round(logistic_roc$auc[1], 2)))), data = logistic_res) + 
  geom_line(aes(x = FPR, y = TPR, color = paste("朴素贝叶斯：","AUC=",as.character(round(nb_roc$auc[1], 2)))), data = nb_res) +
  geom_line(aes(x = FPR, y = TPR, color = paste("决策树：","AUC=",as.character(round(tree_roc$auc[1], 2)))), data = tree_res) + 
  geom_line(aes(x = FPR, y = TPR, color = paste("支持向量机：","AUC=",as.character(round(svm_roc$auc[1], 2)))), data = svm_res) +
  geom_line(aes(x = FPR, y = TPR, color = paste("神经网络：","AUC=",as.character(round(mlp_roc$auc[1], 2)))), data = mlp_res) + 
  theme_bw() + 
  theme(legend.justification = c(1, 0), legend.position = c(1, 0)) + 
  geom_abline(aes(slope = 1, intercept = 0), color = I("gray")) + 
  guides(color = guide_legend(title = NULL))
plot_comparison
```





















